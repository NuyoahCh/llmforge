Overview: A hands-on project to build a retrieval-based chatbot that answers customer questions for an imaginary e-commerce store.

Learning objectives:





Ingest and chunk unstructured documents



Create embeddings and index with FAISS



Retrieve context and design prompts



Run an open-weight LLM locally with Ollama



Build a RAG (Retrieval-Augmented Generation) pipeline



Package the chatbot in a minimal Streamlit UI



Estimated Time Commitment: This project typically takes around 90 minutes, depending on how much time you spend experimenting.

Instructions: Open the notebook on GitHub using the link above. To run locally, clone the repository, open the notebook in Jupyter or VS Code, and run it in your Python environment. Then follow these steps:





Start at the top of the notebook and run every cell in order. 



When you see a comment such as `YOUR CODE HERE` inside a code cell, add the missing lines where the comment appears.  



Experiment. Change decoding settings one at a time (temperature, `top_k`, `top_p`), try a few different prompts, and inspect how tokenization affects outputs.



When you get stuck:





Post your question in the Q/A space and get guidance from the instructor or your peers.



If you can’t resolve the issue, make a note of where you stopped and continue with the next sections. The complete solution will be reviewed during the weekly Project Deep Dive session.



When you cannot complete the project: 





Skim through the notebook to familiarize yourself with the main ideas.  



Join the Project Deep Dive session for a full walkthrough and explanation.  



If you cannot attend live, watch the session recording to catch up at your own pace. 



Start here (full project notebook and instructions): 

https://github.com/bytebyteai/ai-eng-projects/blob/main/project_2/rag_chatbot.ipynb